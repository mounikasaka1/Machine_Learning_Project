{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1) IMPORTS ─────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load built-in datasets\n",
    "iris_df = load_iris(as_frame=True).frame\n",
    "wine_df = load_wine(as_frame=True).frame\n",
    "\n",
    "# Load uploaded real-world dataset\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Build dataset map\n",
    "raw_datasets = {\n",
    "    'Iris': iris_df,\n",
    "    'Wine': wine_df,\n",
    "    'Diabetes': diabetes_df\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, target_col):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop rows with all NaNs and duplicates\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Fill missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [np.float64, np.int64]:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Encode categorical features (if any)\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    # Split into features and target\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Decision Tree': (\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        {'clf__max_depth': [None, 5, 10], 'clf__min_samples_split': [2, 5, 10]}\n",
    "    ),\n",
    "    'Random Forest': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'clf__n_estimators': [50, 100], 'clf__max_depth': [None, 5, 10]}\n",
    "    ),\n",
    "    'KNN': (\n",
    "        KNeighborsClassifier(),\n",
    "        {'clf__n_neighbors': [3, 5, 7]}\n",
    "    ),\n",
    "    'Logistic Regression': (\n",
    "        LogisticRegression(max_iter=1000, random_state=42),\n",
    "        {'clf__C': [0.01, 0.1, 1, 10]}\n",
    "    )\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Iris\n",
      "\n",
      "Processing: Wine\n",
      "\n",
      "Processing: Diabetes\n",
      "     Dataset                Model  \\\n",
      "0       Iris        Decision Tree   \n",
      "1       Iris        Random Forest   \n",
      "2       Iris                  KNN   \n",
      "3       Iris  Logistic Regression   \n",
      "4       Wine        Decision Tree   \n",
      "5       Wine        Random Forest   \n",
      "6       Wine                  KNN   \n",
      "7       Wine  Logistic Regression   \n",
      "8   Diabetes        Decision Tree   \n",
      "9   Diabetes        Random Forest   \n",
      "10  Diabetes                  KNN   \n",
      "11  Diabetes  Logistic Regression   \n",
      "\n",
      "                                          Best Params  Accuracy        F1  \\\n",
      "0   {'clf__max_depth': None, 'clf__min_samples_spl...  1.000000  1.000000   \n",
      "1   {'clf__max_depth': None, 'clf__n_estimators': 50}  1.000000  1.000000   \n",
      "2                             {'clf__n_neighbors': 3}  1.000000  1.000000   \n",
      "3                                       {'clf__C': 1}  1.000000  1.000000   \n",
      "4   {'clf__max_depth': None, 'clf__min_samples_spl...  0.944444  0.944856   \n",
      "5   {'clf__max_depth': None, 'clf__n_estimators': ...  1.000000  1.000000   \n",
      "6                             {'clf__n_neighbors': 5}  0.944444  0.943604   \n",
      "7                                     {'clf__C': 0.1}  1.000000  1.000000   \n",
      "8   {'clf__max_depth': 5, 'clf__min_samples_split'...  0.792208  0.788094   \n",
      "9   {'clf__max_depth': None, 'clf__n_estimators': 50}  0.707792  0.710359   \n",
      "10                            {'clf__n_neighbors': 5}  0.694805  0.689645   \n",
      "11                                     {'clf__C': 10}  0.753247  0.754191   \n",
      "\n",
      "    Precision    Recall       AUC  \n",
      "0    1.000000  1.000000  1.000000  \n",
      "1    1.000000  1.000000  1.000000  \n",
      "2    1.000000  1.000000  1.000000  \n",
      "3    1.000000  1.000000  1.000000  \n",
      "4    0.951389  0.944444  0.954275  \n",
      "5    1.000000  1.000000  1.000000  \n",
      "6    0.949383  0.944444  0.999459  \n",
      "7    1.000000  1.000000  1.000000  \n",
      "8    0.788654  0.792208  0.820753  \n",
      "9    0.714412  0.707792  0.800184  \n",
      "10   0.687444  0.694805  0.764096  \n",
      "11   0.755394  0.753247  0.814325  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name, df in raw_datasets.items():\n",
    "    print(f\"\\nProcessing: {dataset_name}\")\n",
    "    \n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = preprocess_dataset(df, target_columns[dataset_name])\n",
    "        min_class_count = pd.Series(y_train).value_counts().min()\n",
    "        cv_folds = min(5, min_class_count)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            pipe = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            try:\n",
    "                grid = GridSearchCV(pipe, param_grid=param_grid, cv=cv_folds, scoring='accuracy')\n",
    "                grid.fit(X_train, y_train)\n",
    "                y_pred = grid.predict(X_test)\n",
    "\n",
    "                # Safe AUC computation\n",
    "                if hasattr(grid, 'predict_proba'):\n",
    "                    if type_of_target(y_test) == 'binary':\n",
    "                        auc = roc_auc_score(y_test, grid.predict_proba(X_test)[:, 1])\n",
    "                    else:\n",
    "                        auc = roc_auc_score(y_test, grid.predict_proba(X_test), multi_class='ovr')\n",
    "                else:\n",
    "                    auc = None\n",
    "\n",
    "                results.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Model': model_name,\n",
    "                    'Best Params': grid.best_params_,\n",
    "                    'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                    'F1': f1_score(y_test, y_pred, average='weighted'),\n",
    "                    'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "                    'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "                    'AUC': auc\n",
    "                })\n",
    "\n",
    "            except Exception as model_error:\n",
    "                results.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Model': model_name,\n",
    "                    'Error': str(model_error)\n",
    "                })\n",
    "\n",
    "    except Exception as dataset_error:\n",
    "        print(f\"Error processing dataset '{dataset_name}': {dataset_error}\")\n",
    "\n",
    "# Create and display final results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
